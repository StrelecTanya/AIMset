{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "До самого пайплайна нужно загрузить необходимые файлы и создать директории - папку для работы (AIMsetfinder) и внутри нее еще одну папку tmp для хранения временных файлов (!!!! - важно - потому что часть файлов сохраняется туда и потом используется)"
      ],
      "metadata": {
        "id": "-FGg_L_yQj0v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir AIMsetfinder\n",
        "!cd AIMsetfinder\n",
        "!mkdir tmp\n",
        "!cd .."
      ],
      "metadata": {
        "id": "L_wZcEu9RFH6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Скачиваем необходимые файлы"
      ],
      "metadata": {
        "id": "AVJy3bGbRSDC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9owH2j-QuHU8",
        "outputId": "0cfb4307-6d82-4587-a2d3-86e90ed22a9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-06-27 09:58:02--  https://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/integrated_call_samples_v3.20130502.ALL.panel\n",
            "Resolving ftp.1000genomes.ebi.ac.uk (ftp.1000genomes.ebi.ac.uk)... 193.62.193.167\n",
            "Connecting to ftp.1000genomes.ebi.ac.uk (ftp.1000genomes.ebi.ac.uk)|193.62.193.167|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 55156 (54K)\n",
            "Saving to: ‘integrated_call_samples_v3.20130502.ALL.panel’\n",
            "\n",
            "integrated_call_sam 100%[===================>]  53.86K   116KB/s    in 0.5s    \n",
            "\n",
            "2024-06-27 09:58:04 (116 KB/s) - ‘integrated_call_samples_v3.20130502.ALL.panel’ saved [55156/55156]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/integrated_call_samples_v3.20130502.ALL.panel"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -nH --cut-dirs=4 -r -p -e robots=off -A 'ALL.*' https://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KisggDRAaUZ",
        "outputId": "3188d4b0-fc38-4a66-8b8b-82ce5b513867"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-06-27 09:58:07--  https://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/\n",
            "Resolving ftp.1000genomes.ebi.ac.uk (ftp.1000genomes.ebi.ac.uk)... 193.62.193.167\n",
            "Connecting to ftp.1000genomes.ebi.ac.uk (ftp.1000genomes.ebi.ac.uk)|193.62.193.167|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘index.html.tmp’\n",
            "\n",
            "index.html.tmp          [  <=>               ]  19.90K  87.0KB/s    in 0.2s    \n",
            "\n",
            "2024-06-27 09:58:08 (87.0 KB/s) - ‘index.html.tmp’ saved [20382]\n",
            "\n",
            "Removing index.html.tmp since it should be rejected.\n",
            "\n",
            "--2024-06-27 09:58:08--  https://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/?C=N;O=D\n",
            "Reusing existing connection to ftp.1000genomes.ebi.ac.uk:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘index.html?C=N;O=D.tmp’\n",
            "\n",
            "index.html?C=N;O=D.     [ <=>                ]  19.90K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2024-06-27 09:58:08 (582 KB/s) - ‘index.html?C=N;O=D.tmp’ saved [20382]\n",
            "\n",
            "Removing index.html?C=N;O=D.tmp since it should be rejected.\n",
            "\n",
            "--2024-06-27 09:58:08--  https://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/?C=M;O=A\n",
            "Reusing existing connection to ftp.1000genomes.ebi.ac.uk:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘index.html?C=M;O=A.tmp’\n",
            "\n",
            "index.html?C=M;O=A.     [ <=>                ]  19.90K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2024-06-27 09:58:09 (903 KB/s) - ‘index.html?C=M;O=A.tmp’ saved [20382]\n",
            "\n",
            "Removing index.html?C=M;O=A.tmp since it should be rejected.\n",
            "\n",
            "--2024-06-27 09:58:09--  https://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/?C=S;O=A\n",
            "Reusing existing connection to ftp.1000genomes.ebi.ac.uk:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘index.html?C=S;O=A.tmp’\n",
            "\n",
            "index.html?C=S;O=A.     [ <=>                ]  19.90K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2024-06-27 09:58:09 (747 KB/s) - ‘index.html?C=S;O=A.tmp’ saved [20382]\n",
            "\n",
            "Removing index.html?C=S;O=A.tmp since it should be rejected.\n",
            "\n",
            "--2024-06-27 09:58:09--  https://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/?C=D;O=A\n",
            "Reusing existing connection to ftp.1000genomes.ebi.ac.uk:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘index.html?C=D;O=A.tmp’\n",
            "\n",
            "index.html?C=D;O=A.     [ <=>                ]  19.90K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2024-06-27 09:58:09 (962 KB/s) - ‘index.html?C=D;O=A.tmp’ saved [20382]\n",
            "\n",
            "Removing index.html?C=D;O=A.tmp since it should be rejected.\n",
            "\n",
            "--2024-06-27 09:58:09--  https://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/\n",
            "Reusing existing connection to ftp.1000genomes.ebi.ac.uk:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2665 (2.6K) [text/html]\n",
            "Saving to: ‘index.html.tmp’\n",
            "\n",
            "index.html.tmp      100%[===================>]   2.60K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-06-27 09:58:10 (1.07 GB/s) - ‘index.html.tmp’ saved [2665/2665]\n",
            "\n",
            "Removing index.html.tmp since it should be rejected.\n",
            "\n",
            "--2024-06-27 09:58:10--  https://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/ALL.chr1.phase3_shapeit2_mvncall_integrated_v5b.20130502.genotypes.vcf.gz\n",
            "Reusing existing connection to ftp.1000genomes.ebi.ac.uk:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1165011543 (1.1G) [application/x-gzip]\n",
            "Saving to: ‘ALL.chr1.phase3_shapeit2_mvncall_integrated_v5b.20130502.genotypes.vcf.gz’\n",
            "\n",
            "ALL.chr1.phase3_sha 100%[===================>]   1.08G  16.8MB/s    in 72s     \n",
            "\n",
            "2024-06-27 09:59:22 (15.4 MB/s) - ‘ALL.chr1.phase3_shapeit2_mvncall_integrated_v5b.20130502.genotypes.vcf.gz’ saved [1165011543/1165011543]\n",
            "\n",
            "--2024-06-27 09:59:22--  https://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/ALL.chr1.phase3_shapeit2_mvncall_integrated_v5b.20130502.genotypes.vcf.gz.tbi\n",
            "Reusing existing connection to ftp.1000genomes.ebi.ac.uk:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 224369 (219K) [application/x-gzip]\n",
            "Saving to: ‘ALL.chr1.phase3_shapeit2_mvncall_integrated_v5b.20130502.genotypes.vcf.gz.tbi’\n",
            "\n",
            "ALL.chr1.phase3_sha 100%[===================>] 219.11K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-06-27 09:59:22 (202 MB/s) - ‘ALL.chr1.phase3_shapeit2_mvncall_integrated_v5b.20130502.genotypes.vcf.gz.tbi’ saved [224369/224369]\n",
            "\n",
            "--2024-06-27 09:59:22--  https://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/ALL.chr2.phase3_shapeit2_mvncall_integrated_v5b.20130502.genotypes.vcf.gz\n",
            "Reusing existing connection to ftp.1000genomes.ebi.ac.uk:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1255861869 (1.2G) [application/x-gzip]\n",
            "Saving to: ‘ALL.chr2.phase3_shapeit2_mvncall_integrated_v5b.20130502.genotypes.vcf.gz’\n",
            "\n",
            "  ALL.chr2.phase3_s   0%[                    ]   7.25M  2.17MB/s    eta 9m 8s  ^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Практическая работа. Работа с библиотекой."
      ],
      "metadata": {
        "id": "wwmbfDmEJTaY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import hail as hl\n",
        "hl.init()\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import re"
      ],
      "metadata": {
        "id": "xpMZN3V9u5AY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare - удаляем группу AMR (смешанные американцы) и создаем тестовую и обучающую выборки"
      ],
      "metadata": {
        "id": "iUptTgbT58G0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!grep -E 'AFR|EUR|SAS|EAS' annotation.txt > annotation_noAMR.txt"
      ],
      "metadata": {
        "id": "sCsCASnH6j-k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec20d014-a075-4dab-9475-27d4e877f833"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "grep: annotation.txt: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "STEP0 - отбираем только би-аллельные SNP и убирает инделы"
      ],
      "metadata": {
        "id": "9gB7h3gBVaBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chr1 = hl.import_vcf('ALL.chr1.phase3_shapeit2_mvncall_integrated_v5b.20130502.genotypes.vcf.gz', force_bgz=True)"
      ],
      "metadata": {
        "id": "l4zrt36avAvQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b134ef51-fa28-43f9-97a0-58cb3d76554b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Initializing Hail with default parameters...\n",
            "Running on Apache Spark version 3.5.1\n",
            "SparkUI available at http://a298ff5653ee:4040\n",
            "Welcome to\n",
            "     __  __     <>__\n",
            "    / /_/ /__  __/ /\n",
            "   / __  / _ `/ / /\n",
            "  /_/ /_/\\_,_/_/_/   version 0.2.131-11d9b2ff89da\n",
            "LOGGING: writing to /content/hail-20240627-1002-0.2.131-11d9b2ff89da.log\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#only bi-allelic SNP\n",
        "chr1 = chr1.filter_rows(hl.len(chr1.alleles) == 2)\n",
        "#remove indels\n",
        "chr1 = chr1.filter_rows(hl.is_snp(chr1.alleles[0], chr1.alleles[1]))"
      ],
      "metadata": {
        "id": "GNwD5WLzEBZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Получаем тестовую и обучающую выборку\n",
        "#Обозначение переменных\n",
        "testindsperdeme = 100\n",
        "demes = 5\n",
        "filenameInds = \"integrated_call_samples_v3.20130502.ALL.panel\"\n",
        "filenameIndsTest = \"annotationTest.txt\"\n",
        "filenameIndsTraining = \"annotationTraining.txt\"\n",
        "\n",
        "\n",
        "size = [testindsperdeme for i in range(demes)]\n",
        "a = pd.read_csv(filenameInds, sep='\\t' )\n",
        "pops = np.sort(np.unique(a.iloc[:, 2]))\n",
        "inds = a.iloc[:, [0, 2]]\n",
        "noinds = np.zeros(len(pops), dtype=int)\n",
        "testset, trainingset = [], []\n",
        "\n",
        "for i in range(len(pops)):\n",
        "    indslocal = inds[inds.iloc[:, 1] == pops[i]].iloc[:, 0]\n",
        "    noinds[i] = np.sum(inds.iloc[:, 1] == pops[i])\n",
        "    s = np.random.choice(noinds[i], size[i], replace=False)\n",
        "    testset.extend(indslocal.iloc[s])\n",
        "    trainingset.extend(indslocal.iloc[np.setdiff1d(np.arange(noinds[i]), s)])\n",
        "\n",
        "#Создаем пустые файлы с заголовком\n",
        "os.system(f\" head -n 1 {filenameInds} > {filenameIndsTest}\")\n",
        "os.system(f\" head -n 1 {filenameInds} > {filenameIndsTraining}\")\n",
        "\n",
        "#Создаем файлы с аннотацией образцов для обучающего и тестового образца по отобранным именам\n",
        "for test_id in testset:\n",
        "    os.system(f\"grep -w {test_id} {filenameInds} >> {filenameIndsTest}\")\n",
        "\n",
        "for train_id in trainingset:\n",
        "    os.system(f\"grep -w {train_id} {filenameInds} >> {filenameIndsTraining}\")"
      ],
      "metadata": {
        "id": "yuAAy-D7Dao3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "STEP1 - считаем частоты SNP"
      ],
      "metadata": {
        "id": "s4MBw12RVne6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "table = hl.import_table(\"integrated_call_samples_v3.20130502.ALL.panel\").key_by(\"sample\")\n",
        "mt = chr1\n",
        "\n",
        "# объединяем данные из аннотации с данными из vcf файла\n",
        "mt = mt.annotate_cols(pheno=table[mt.s])\n",
        "\n",
        "#Список популяций в файле\n",
        "pops = list(table.aggregate(hl.agg.collect_as_set(table.super_pop)))\n",
        "\n",
        "# Инициализация таблицы первой популяцией\n",
        "mt_pop = mt.filter_cols(mt.pheno.super_pop == pops[0])\n",
        "mt_pop = hl.variant_qc(mt_pop)\n",
        "mt_pop = mt_pop.annotate_rows(alt = mt_pop.variant_qc.AF[1])\n",
        "freq_table = mt_pop.rows().select('alt').rename({\"alt\": f'{pops[0]}'})\n",
        "\n",
        "# Цикл по оставшимся популяциям\n",
        "for pop in pops[1:]:\n",
        "  mt_pop = mt.filter_cols(mt.pheno.super_pop == pop)\n",
        "  mt_pop = hl.variant_qc(mt_pop)\n",
        "  mt_pop = mt_pop.annotate_rows(alt = mt_pop.variant_qc.AF[1])\n",
        "  pop_freq = mt_pop.rows().select('alt').rename({\"alt\": f'{pop}'})\n",
        "\n",
        "  # Объединяем таблицы\n",
        "  freq_table = freq_table.join(pop_freq)"
      ],
      "metadata": {
        "id": "iV5UE7sgNj0S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24469fa2-531d-4bea-fe19-b8a63aa6c5bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-06-27 10:11:52.757 Hail: INFO: Reading table without type imputation\n",
            "  Loading field 'sample' as type str (not specified)\n",
            "  Loading field 'pop' as type str (not specified)\n",
            "  Loading field 'super_pop' as type str (not specified)\n",
            "  Loading field 'gender' as type str (not specified)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "freq_table.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "l7XZ1VtYLpMu",
        "outputId": "5b5bc541-902a-4de8-8ae6-752c116f2957"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-06-27 10:12:47.550 Hail: INFO: scanning VCF for sortedness...\n",
            "2024-06-27 10:15:54.635 Hail: INFO: Coerced prefix-sorted VCF, requiring additional sorting within data partitions on each query.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "+---------------+------------+----------+----------+----------+----------+----------+\n",
              "| locus         | alleles    |      SAS |      AFR |      AMR |      EAS |      EUR |\n",
              "+---------------+------------+----------+----------+----------+----------+----------+\n",
              "| locus<GRCh37> | array<str> |  float64 |  float64 |  float64 |  float64 |  float64 |\n",
              "+---------------+------------+----------+----------+----------+----------+----------+\n",
              "| 1:10505       | [\"A\",\"T\"]  | 0.00e+00 | 7.56e-04 | 0.00e+00 | 0.00e+00 | 0.00e+00 |\n",
              "| 1:10506       | [\"C\",\"G\"]  | 0.00e+00 | 7.56e-04 | 0.00e+00 | 0.00e+00 | 0.00e+00 |\n",
              "| 1:10511       | [\"G\",\"A\"]  | 0.00e+00 | 0.00e+00 | 1.44e-03 | 0.00e+00 | 0.00e+00 |\n",
              "| 1:10539       | [\"C\",\"A\"]  | 1.02e-03 | 0.00e+00 | 1.44e-03 | 0.00e+00 | 9.94e-04 |\n",
              "| 1:10542       | [\"C\",\"T\"]  | 0.00e+00 | 0.00e+00 | 0.00e+00 | 9.92e-04 | 0.00e+00 |\n",
              "| 1:10579       | [\"C\",\"A\"]  | 0.00e+00 | 7.56e-04 | 0.00e+00 | 0.00e+00 | 0.00e+00 |\n",
              "| 1:10642       | [\"G\",\"A\"]  | 0.00e+00 | 1.29e-02 | 1.44e-03 | 2.98e-03 | 0.00e+00 |\n",
              "| 1:11008       | [\"C\",\"G\"]  | 7.16e-02 | 1.35e-01 | 9.65e-02 | 3.67e-02 | 8.85e-02 |\n",
              "| 1:11012       | [\"C\",\"G\"]  | 7.16e-02 | 1.35e-01 | 9.65e-02 | 3.67e-02 | 8.85e-02 |\n",
              "| 1:11063       | [\"T\",\"G\"]  | 0.00e+00 | 1.06e-02 | 1.44e-03 | 0.00e+00 | 0.00e+00 |\n",
              "+---------------+------------+----------+----------+----------+----------+----------+\n",
              "showing top 10 rows"
            ],
            "text/html": [
              "<table><thead><tr><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \" colspan=\"1\"><div style=\"text-align: left;\"></div></td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \" colspan=\"1\"><div style=\"text-align: left;\"></div></td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \" colspan=\"1\"><div style=\"text-align: left;\"></div></td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \" colspan=\"1\"><div style=\"text-align: left;\"></div></td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \" colspan=\"1\"><div style=\"text-align: left;\"></div></td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \" colspan=\"1\"><div style=\"text-align: left;\"></div></td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \" colspan=\"1\"><div style=\"text-align: left;\"></div></td></tr><tr><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \" colspan=\"1\"><div style=\"text-align: left;border-bottom: solid 2px #000; padding-bottom: 5px\">locus</div></td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \" colspan=\"1\"><div style=\"text-align: left;border-bottom: solid 2px #000; padding-bottom: 5px\">alleles</div></td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \" colspan=\"1\"><div style=\"text-align: left;border-bottom: solid 2px #000; padding-bottom: 5px\">SAS</div></td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \" colspan=\"1\"><div style=\"text-align: left;border-bottom: solid 2px #000; padding-bottom: 5px\">AFR</div></td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \" colspan=\"1\"><div style=\"text-align: left;border-bottom: solid 2px #000; padding-bottom: 5px\">AMR</div></td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \" colspan=\"1\"><div style=\"text-align: left;border-bottom: solid 2px #000; padding-bottom: 5px\">EAS</div></td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \" colspan=\"1\"><div style=\"text-align: left;border-bottom: solid 2px #000; padding-bottom: 5px\">EUR</div></td></tr><tr><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; text-align: left;\">locus&lt;GRCh37&gt;</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; text-align: left;\">array&lt;str&gt;</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; text-align: left;\">float64</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; text-align: left;\">float64</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; text-align: left;\">float64</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; text-align: left;\">float64</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; text-align: left;\">float64</td></tr>\n",
              "</thead><tbody><tr><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">1:10505</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">[&quot;A&quot;,&quot;T&quot;]</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">0.00e+00</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">7.56e-04</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">0.00e+00</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">0.00e+00</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">0.00e+00</td></tr>\n",
              "<tr><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">1:10506</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">[&quot;C&quot;,&quot;G&quot;]</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">0.00e+00</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">7.56e-04</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">0.00e+00</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">0.00e+00</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">0.00e+00</td></tr>\n",
              "<tr><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">1:10511</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">[&quot;G&quot;,&quot;A&quot;]</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">0.00e+00</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">0.00e+00</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">1.44e-03</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">0.00e+00</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">0.00e+00</td></tr>\n",
              "<tr><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">1:10539</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">[&quot;C&quot;,&quot;A&quot;]</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">1.02e-03</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">0.00e+00</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">1.44e-03</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">0.00e+00</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">9.94e-04</td></tr>\n",
              "<tr><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">1:10542</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">[&quot;C&quot;,&quot;T&quot;]</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">0.00e+00</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">0.00e+00</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">0.00e+00</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">9.92e-04</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">0.00e+00</td></tr>\n",
              "<tr><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">1:10579</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">[&quot;C&quot;,&quot;A&quot;]</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">0.00e+00</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">7.56e-04</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">0.00e+00</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">0.00e+00</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">0.00e+00</td></tr>\n",
              "<tr><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">1:10642</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">[&quot;G&quot;,&quot;A&quot;]</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">0.00e+00</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">1.29e-02</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">1.44e-03</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">2.98e-03</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">0.00e+00</td></tr>\n",
              "<tr><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">1:11008</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">[&quot;C&quot;,&quot;G&quot;]</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">7.16e-02</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">1.35e-01</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">9.65e-02</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">3.67e-02</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">8.85e-02</td></tr>\n",
              "<tr><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">1:11012</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">[&quot;C&quot;,&quot;G&quot;]</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">7.16e-02</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">1.35e-01</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">9.65e-02</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">3.67e-02</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">8.85e-02</td></tr>\n",
              "<tr><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">1:11063</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">[&quot;T&quot;,&quot;G&quot;]</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">0.00e+00</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">1.06e-02</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">1.44e-03</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">0.00e+00</td><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">0.00e+00</td></tr>\n",
              "</tbody></table><p style=\"background: #fdd; padding: 0.4em;\">showing top 10 rows</p>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "STEP2 - фильтрация SNP по информативности"
      ],
      "metadata": {
        "id": "8syXLxsiNocO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Задаем уровень информативности, при котором мы оставляем SNP\n",
        "informativenessBound = 0.9\n",
        "#Вводим дополнительные функции для подсчета информативности\n",
        "def xlogx2(x):\n",
        "    z = xlogx(x) + xlogx(1 - x)\n",
        "    return z\n",
        "\n",
        "def xlogx(x):\n",
        "    z = hl.if_else(x == 0, 0, x * hl.log(x))\n",
        "    return z\n",
        "#Считаем количесвто строк в файле\n",
        "nss = freq_table.count()\n",
        "#Считаем средние\n",
        "freq_table = freq_table.annotate(\n",
        "    mean_row=(freq_table.AFR + freq_table.SAS + freq_table.EUR + freq_table.AMR + freq_table.EAS) / len(pops)\n",
        ")\n",
        "freq_table = freq_table.annotate(\n",
        "    mean_row_log=(xlogx2(freq_table.AFR) + xlogx2(freq_table.SAS) + xlogx2(freq_table.EUR) + xlogx2(freq_table.AMR) + xlogx2(freq_table.EAS)) / len(pops)\n",
        ")\n",
        "#Считаем информативность\n",
        "freq_table = freq_table.annotate(info= -xlogx2(freq_table.mean_row) + freq_table.mean_row_log)\n",
        "#Фильтруем таблицу по информативности (в порядке убывания) и отбираем 10% самых информативных SNP\n",
        "informativenessQuantile = freq_table.order_by(hl.desc(freq_table.info)).head(hl.eval(hl.int32(hl.floor((1 - informativenessBound)* nss))))\n",
        "#Создаем новый vcf-файл с отобранными SNP по информативности\n",
        "informativenessQuantile = informativenessQuantile.key_by(\"locus\")\n",
        "mt = chr1.filter_rows(hl.is_defined(informativenessQuantile[chr1.locus]))\n",
        "#Сохраняем файл\n",
        "hl.export_vcf(mt, 'tmp/filter_chr1.vcf.bgz')"
      ],
      "metadata": {
        "id": "HDuQu4q-Nvk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "STEP3 - делим имеющийся файл на маленькие"
      ],
      "metadata": {
        "id": "iQjfMknnN1Eu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mt = hl.import_vcf('tmp/filter_chr1.vcf.bgz')\n",
        "stepsize = 10000\n",
        "# Вычисляем количество сегментов и преобразуем в список\n",
        "segments = hl.range(0, hl.int32((mt.count_rows() - 1) // stepsize + 1)).collect()\n",
        "# Добавляем столбец с номером строки\n",
        "mt = mt.annotate_rows(row_index=hl.scan.count())\n",
        "\n",
        "# Фильтруем строки по номеру\n",
        "\n",
        "# Цикл по сегментам\n",
        "for j in segments[0]:\n",
        "    start = j * stepsize\n",
        "    end = hl.eval(min((j + 1) * stepsize, mt.count_rows()))\n",
        "    # Фильтруем строки по номеру\n",
        "    segment_mt = mt.filter_rows((mt.row.row_index >= start) & (mt.row.row_index < end))\n",
        "    hl.export_vcf(segment_mt, f\"tmp/chr_segment{j}.vcf.bgz\")"
      ],
      "metadata": {
        "id": "NLECQ8f7N5RJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "STEP4 - считаем кол-во строк в новом vcf файле"
      ],
      "metadata": {
        "id": "885FjwMKN8qj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nss = hl.eval(mt.count()[0])"
      ],
      "metadata": {
        "id": "dBnK-WA7OAGd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "STEP5 - переводим vcf.gz файлы в hail matrix table для более быстрого чтения"
      ],
      "metadata": {
        "id": "e4YCofyUfWr0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def genotype_to_number(gt):\n",
        "    z = hl.case().when(gt.is_het(), 1).when(gt.is_hom_ref(), 0).when(gt.is_hom_var(), 2).or_missing()\n",
        "    return z\n",
        "#Создаем список имен файлов для шага 6\n",
        "filenames = []\n",
        "for j in segments[0]:\n",
        "    mt = hl.import_vcf(f\"tmp/chr_segment{j}.vcf.bgz\")\n",
        "    mt = mt.annotate_entries(GT=genotype_to_number(mt.GT))\n",
        "    mt.write(f'tmp/chr_segment{j}.mt', overwrite=True)\n",
        "    filenames.append(f'tmp/chr_segment{j}')"
      ],
      "metadata": {
        "id": "-VZbPGHLDGg7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "STEP6 - получаем список AIMs по обучающей выборке"
      ],
      "metadata": {
        "id": "E5FJEdPCgvEp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функции для 6го шага"
      ],
      "metadata": {
        "id": "EcpNGJmPhDX0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_aims_hail(filenames_mt, table, num_aim, sampleAIMs):\n",
        "    \"\"\"\n",
        "    Находит AIMs (Ancestry Informative Markers) из списка Hail Matrix Table.\n",
        "\n",
        "    Args:\n",
        "        filenames_mt: Список путей к файлам Hail Matrix Table.\n",
        "        table: Hail Table с информацией о популяциях.\n",
        "        num_aim: Количество AIMs для поиска.\n",
        "        sampleAIMs: файл, куда будут складываться AIMs\n",
        "\n",
        "    Returns:\n",
        "        Hail Matrix Table с выбранными AIMs.\n",
        "    \"\"\"\n",
        "\n",
        "    while len(sampleAIMs) < num_aim:\n",
        "        best = []\n",
        "        all_errors = []\n",
        "        for filename in filenames_mt:\n",
        "            best_snp, error = find_next_AIM(filename, sampleAIMs, table)\n",
        "            best.append(best_snp)\n",
        "            all_errors.append(error)\n",
        "        #Находим AIM  с минимальной ошибкой\n",
        "        best_aim = best[all_errors.index(min(all_errors))]\n",
        "        #Добавляем лучший SNP к таблице AIMs\n",
        "        sampleAIMs.append(best_aim)\n",
        "        best.remove(best_aim )\n",
        "        all_errors.remove(min(all_errors))\n",
        "\n",
        "    return sampleAIMs\n",
        "\n",
        "def find_next_AIM(filename, sampleAIMs, table):\n",
        "    samples_in_deme = table.aggregate(hl.agg.counter(table.super_pop))\n",
        "    no = hl.if_else(len(sampleAIMs) == 0, 0, len(sampleAIMs))\n",
        "    sample = hl.read_matrix_table(f'{filename}.mt')\n",
        "    sample_vcf= hl.import_vcf(f'{filename}.vcf.bgz')\n",
        "    freqs_training = getfreqs(sample_vcf, table)\n",
        "\n",
        "    error = []\n",
        "    for i in range(sample.count_rows()):\n",
        "        snp_num = i\n",
        "        e = App_test_error(sample, freqs_training, sample_names, snp_num, table)\n",
        "        error.append(e)\n",
        "\n",
        "    min_error = min(error)\n",
        "    best_snp = error.index(min_error) #находим snp с минимальной ошибкой\n",
        "    #ищем название snp\n",
        "    locus_list = sample_vcf.locus.collect()\n",
        "    sample_next_AIM = locus_list[best_snp]\n",
        "    #return sample_next_AIM, min_error\n",
        "    return sample_next_AIM, min_error\n",
        "\n",
        "def getfreqs(mt, table_annotation): # mt - .vcf.gz файлы из шага 5, table_annotation - это таблица с описанием образцов\n",
        "    locus_list = mt.locus.collect()\n",
        "    #объединяем данные из аннотации с данными из vcf файла\n",
        "    mt = mt.annotate_cols(pheno=table_annotation[mt.s])\n",
        "\n",
        "    #Список популяций в файле\n",
        "    pops = list(table_annotation.aggregate(hl.agg.collect_as_set(table_annotation.super_pop)))\n",
        "\n",
        "    # Инициализация таблицы первой популяцией\n",
        "    mt_pop = mt.filter_cols(mt.pheno.super_pop == pops[0])\n",
        "    mt_pop = hl.variant_qc(mt_pop)\n",
        "    mt_pop = mt_pop.annotate_rows(alt = mt_pop.variant_qc.AC[1]).key_rows_by(\"locus\")\n",
        "    freq_list = mt_pop.alt.collect()\n",
        "    locus_freq_table = hl.Table.parallelize(\n",
        "        [{\"locus\": locus, \"frequency\": freq} for locus, freq in zip(locus_list, freq_list)],\n",
        "        hl.tstruct(locus=hl.tlocus(\"GRCh37\"), frequency=hl.tint32),\n",
        "    ).rename({\"frequency\": f'{pops[0]}'})\n",
        "    table = locus_freq_table.key_by(\"locus\")\n",
        "    # Цикл по оставшимся популяциям\n",
        "    for pop in pops[1:]:\n",
        "        mt_pop = mt.filter_cols(mt.pheno.super_pop == pop)\n",
        "        mt_pop = hl.variant_qc(mt_pop)\n",
        "        mt_pop = mt_pop.annotate_rows(alt = mt_pop.variant_qc.AC[1]).key_rows_by(\"locus\")\n",
        "        freq_list = mt_pop.alt.collect()\n",
        "        locus_freq_table = hl.Table.parallelize(\n",
        "            [{\"locus\": locus, \"frequency\": freq} for locus, freq in zip(locus_list, freq_list)],\n",
        "            hl.tstruct(locus=hl.tlocus(\"GRCh37\"), frequency=hl.tint32)).rename({\"frequency\": f'{pop}'}).key_by(\"locus\")\n",
        "        table = table.join(locus_freq_table, how=\"left\")\n",
        "    return table\n",
        "\n",
        "def log_prediction_naiveBayes(sample_test, table_with_freq, sample_names, number_of_snp):\n",
        "  res = np.zeros((len(sample_names), 5))\n",
        "  for j in range(len(sample_names)):\n",
        "    selected_mt = sample_test.filter_cols(sample_test.s == f'{sample_names[j]}').GT.collect()[number_of_snp]\n",
        "    for k in range(5):\n",
        "      counts = [int(re.search(r'\\d+(\\.\\d+)?', str(i)).group(0)) for i in table_with_freq.select(f\"{pops[k]}\").collect()][number_of_snp]\n",
        "      res[j, :][k] += np.log(1 + counts) * selected_mt + np.log((1 + diploid) * samples_in_deme[pops[k]] - counts + 1) * (1 + diploid - selected_mt)\n",
        "  else:\n",
        "    return res\n",
        "\n",
        "def prediction_naive_bayes(sample_test, counts, sample_names, number_of_snp):\n",
        "  res = log_prediction_naiveBayes(sample_test, counts, sample_names, number_of_snp)\n",
        "  # Вычисляем экспоненту для каждого значения в res, вычитая максимальное значение\n",
        "  res = np.exp(res - np.max(res))\n",
        "  # Нормализуем каждую строку так, чтобы сумма элементов в строке была равна 1\n",
        "  res = res / res.sum(axis=1, keepdims=True)\n",
        "  return res\n",
        "\n",
        "def logloss_error(prediction_table):\n",
        "  \"\"\"\n",
        "  Вычисляет logloss error для Hail Table с вероятностями.\n",
        "\n",
        "  Args:\n",
        "      prediction_table (Hail Table): Таблица, содержащая столбцы с вероятностями\n",
        "          принадлежности к популяциям и столбец 'super_pop' с истинными классами.\n",
        "\n",
        "  Returns:\n",
        "      float: Значение logloss error.\n",
        "  \"\"\"\n",
        "\n",
        "  # Получаем список названий популяций из колонок\n",
        "  populations = ['EAS', 'SAS', 'AFR', 'EUR', 'AMR']\n",
        "\n",
        "  # Создаем список выражений для получения вероятности для истинного класса\n",
        "  probs_for_correct_classes_expr = [\n",
        "    hl.if_else(prediction_table.super_pop == population,\n",
        "               prediction_table[population],\n",
        "               hl.literal(0))\n",
        "    for population in populations\n",
        "  ]\n",
        "\n",
        "  # Вычисляем среднее логарифма вероятности для истинного класса\n",
        "  logloss = - prediction_table.aggregate(hl.agg.mean(hl.log(hl.sum(probs_for_correct_classes_expr))))\n",
        "\n",
        "  return logloss\n",
        "\n",
        "def App_test_error(sample_test, counts, sample_names, number_of_snp, table):\n",
        "    \"\"\"\n",
        "  Вычисляет ошибку для каждого SNP\n",
        "\n",
        "  Args:\n",
        "     sample_test - matrix table по типу vcf.gz только генотипы 0, 1, 2 - получен на 5м шаге\n",
        "     counts - hail table с частотами каждого SNP в популяциях\n",
        "     sample_names - имя образцов для обучающей выборки\n",
        "     number_of_snp - для какого SNP считаем вероятности\n",
        "     table - hail table = annotationTraining.txt\n",
        "\n",
        "  Returns:\n",
        "    Значение logloss error для каждого SNP в файле.\n",
        "  \"\"\"\n",
        "    #Считаем матрицу вероятностей\n",
        "    res = prediction_naive_bayes(sample_test, counts, sample_names, number_of_snp)\n",
        "    # Преобразуем numpy массив в pandas DataFrame\n",
        "    df = pd.DataFrame(res, columns=pops)\n",
        "    #Добавляем колонку с именами образцов\n",
        "    df[\"sample\"] = sample_names\n",
        "    #Добавляем колонку с именами популяций\n",
        "    population = table.super_pop.collect()\n",
        "    df[\"super_pop\"] = population\n",
        "    ht = hl.Table.from_pandas(df)\n",
        "    error = logloss_error(ht)\n",
        "    return error"
      ],
      "metadata": {
        "id": "-SPxaqv4DQiS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d8f6b5f-1b31-414e-e5c3-73be343148cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-06-26 05:47:42.930 Hail: WARN: Name collision: field 'sample' already in object dict. \n",
            "  This field must be referenced with __getitem__ syntax: obj['sample']\n",
            "2024-06-26 05:47:42.941 Hail: INFO: Reading table without type imputation\n",
            "  Loading field 'sample' as type str (not specified)\n",
            "  Loading field 'pop' as type str (not specified)\n",
            "  Loading field 'super_pop' as type str (not specified)\n",
            "  Loading field 'gender' as type str (not specified)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сам 6ой шаг\n"
      ],
      "metadata": {
        "id": "lBX8cL_ZhkVl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = hl.import_table(\"annotationTraining.txt\").select(\"sample\",\"super_pop\").key_by(\"sample\")\n",
        "#Создаем список с именами все анализируемых vcf файлов - шаг 5 - filenames\n",
        "#Вводим глобальные переменнные\n",
        "diploid = True\n",
        "sample_names = [(re.search(r\"Struct\\(sample='(.*?)'\\)\", str(i)).group(1)) for i in a.key_by().select(\"sample\").collect()]\n",
        "#Количесвто AIM, которое мы хотим получить в итоге\n",
        "numAIM = 10\n",
        "#Частота встречаемости популяций - словарь\n",
        "samples_in_deme = a.aggregate(hl.agg.counter(a.super_pop))\n",
        "#Создаем пустой список для хранения названий информативных маркеров\n",
        "sampleAIMs = []\n",
        "pops = list(a.aggregate(hl.agg.collect_as_set(a.super_pop)))\n",
        "#Ищем AIMset\n",
        "sampleAIMs = find_aims_hail(filenames, a, numAIM, sampleAIMs)"
      ],
      "metadata": {
        "id": "2y7DmPKChj27"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}